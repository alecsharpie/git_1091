def clean_text(text):
    return text.lower()

def tokenizer(text):
     return text.split(' ')
